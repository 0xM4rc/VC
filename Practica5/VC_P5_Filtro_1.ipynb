{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro emoji según estado de ánimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprobación de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731548395.762875   19547 gpu_device.cc:2022] Created device /device:GPU:0 with 683 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import cairosvg\n",
    "\n",
    "# Factor de escala para agrandar el ícono\n",
    "icon_scale_factor = 1.2\n",
    "\n",
    "# Función para cargar y convertir un archivo SVG en un PNG compatible con OpenCV\n",
    "def load_svg_to_opencv(path, width, height):\n",
    "    # Ajustar el ancho y alto al factor de escala\n",
    "    width = int(width * icon_scale_factor)\n",
    "    height = int(height * icon_scale_factor)\n",
    "    \n",
    "    # Convierte el SVG a PNG en memoria\n",
    "    png_data = cairosvg.svg2png(url=path, output_width=width, output_height=height)\n",
    "    \n",
    "    # Convertir PNG en datos de imagen para OpenCV\n",
    "    nparr = np.frombuffer(png_data, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED)  # Lee la imagen con transparencia (canal alpha)\n",
    "    return img\n",
    "\n",
    "# Diccionario de iconos de emociones usando SVGs\n",
    "emotion_icons = {\n",
    "    \"happy\": \"/home/m4rc/Desktop/VC/Ejercicios Practicas/Practica5/assets/emojis/1f604.svg\",\n",
    "    \"sad\": \"/home/m4rc/Desktop/VC/Ejercicios Practicas/Practica5/assets/emojis/1f622.svg\",\n",
    "    \"angry\": \"/home/m4rc/Desktop/VC/Ejercicios Practicas/Practica5/assets/emojis/1f621.svg\",\n",
    "    \"surprise\": \"/home/m4rc/Desktop/VC/Ejercicios Practicas/Practica5/assets/emojis/1f62f.svg\",\n",
    "    \"neutral\": \"/home/m4rc/Desktop/VC/Ejercicios Practicas/Practica5/assets/emojis/1f610.svg\"\n",
    "}\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Iniciar captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturar fotograma\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Duplicar el fotograma original para tener uno sin el efecto\n",
    "    original_frame = frame.copy()\n",
    "\n",
    "    # Convertir el fotograma a escala de grises\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convertir el fotograma en escala de grises a RGB\n",
    "    rgb_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Detectar rostros en el fotograma\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extraer la región de interés del rostro\n",
    "        face_roi = rgb_frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Realizar el análisis de emociones en la ROI\n",
    "        result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "        # Obtener la emoción dominante\n",
    "        emotion = result[0]['dominant_emotion']\n",
    "        \n",
    "        # Verificar si hay un ícono para la emoción detectada y cargarlo\n",
    "        if emotion in emotion_icons:\n",
    "            icon_path = emotion_icons[emotion]\n",
    "            \n",
    "            # Cargar y redimensionar el ícono SVG a PNG con un tamaño más grande\n",
    "            icon_resized = load_svg_to_opencv(icon_path, w, h)\n",
    "\n",
    "            # Calcular la posición para centrar el ícono más grande en el rostro\n",
    "            y_offset = y - int((icon_resized.shape[0] - h) / 2)\n",
    "            x_offset = x - int((icon_resized.shape[1] - w) / 2)\n",
    "\n",
    "            # Ajustar los límites si están fuera de los límites del fotograma\n",
    "            y1, y2 = max(y_offset, 0), min(y_offset + icon_resized.shape[0], frame.shape[0])\n",
    "            x1, x2 = max(x_offset, 0), min(x_offset + icon_resized.shape[1], frame.shape[1])\n",
    "            icon_y1, icon_y2 = 0, y2 - y1\n",
    "            icon_x1, icon_x2 = 0, x2 - x1\n",
    "\n",
    "            # Superponer el ícono en la imagen principal\n",
    "            for c in range(0, 3):  # Aplicar sobre cada canal de color\n",
    "                frame[y1:y2, x1:x2, c] = np.where(\n",
    "                    icon_resized[icon_y1:icon_y2, icon_x1:icon_x2, 3] > 0,  # Verifica el canal alpha\n",
    "                    icon_resized[icon_y1:icon_y2, icon_x1:icon_x2, c],\n",
    "                    frame[y1:y2, x1:x2, c]\n",
    "                )\n",
    "\n",
    "    # Mostrar el fotograma con efecto y el original en dos ventanas separadas\n",
    "    cv2.imshow('Real-time Emotion Detection (with effect)', frame)\n",
    "    cv2.imshow('Original Camera View', original_frame)\n",
    "\n",
    "    # Presionar 'q' para salir\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la captura y cerrar todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
